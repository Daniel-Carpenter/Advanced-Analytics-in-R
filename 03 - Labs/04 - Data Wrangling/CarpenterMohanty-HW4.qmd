---
title: "Homework 4 - Data Wrangling in R"
author: "Daniel Carpenter & Sonaxy Mohanty"
date: "September 2022"
format: 
  pdf:
    toc: true
    toc-depth: 2
    # number-sections: true
    highlight-style: github #arrow
    code-block-border-left: "#D6D6D6"
  gfm:
    toc: true
    toc-depth: 1
    
execution:
  echo:    true
  include: true
  cache:   true
  message: false
  warning: false

editor: visual

fig-width:  7
fig-height: 3.5
---

\newpage

## Packages

```{r, message=FALSE}
# Data Wrangling
library(tidyverse)

# Modeling
library(car)      # symbox 
library(EnvStats) # boxcox function
library(mice)     # Predictive mean matching for missing values

# Aesthetics
library(cowplot)  # multiple ggplots on one plot with plot_grid()
library(scales)
```

# `1` - Data Quality Report

## `1 (a)` - Read data

```{r}
# Read data
housingData <- read_csv('housingData.csv')

# create three new variables
housingData <- housingData %>%
  dplyr::mutate(age             = YrSold - YearBuilt,
                ageSinceRemodel = YrSold - YearRemodAdd,
                ageofGarage     = YrSold - GarageYrBlt
                )
```

## `1 (b)` - Numeric Housing Tibble

-   Create a tibble named `housingNumeric` which contains all of the numeric variables from the original data.

-   use the `dplyr::select` command along with the `is.numeric` function to complete this task.

```{r}
# Convert df to a tibble
housingNumeric <- as_tibble(housingData) %>%
  
  # Only select numeric data 
  # note would usually use command select_if(is.numeric)
  select(where(is.numeric))
```

## `1 (c)` - Factor Housing Tibble

-   create a tibble named `housingFactor` which contains all of the character variables from the original data.

```{r}
housingFactor <- as_tibble(housingData) %>%
  
  # Change all character variables to factors
  # Keep only the changed data. Implicitly keeping only factor (prev. char vars)
  transmute_if(is.character, as.factor) 
```

## `1 (d)` - Use Glimpse

```{r}
# NOT RUN
# glimpse(housingNumeric)
# glimpse(housingFactor)
```

## `1 (e)` - Get Q1 and Q3

-   create our own user-defined functions for extracting only first and 3rd quantile

-   Explanation: Gets the quantiles of a vector using quantile function, but we use the `[]` brackets to retrieve the 2nd or 4th objects in the vector, which are `Q1` and `Q3`

```{r}
Q1 <- function(x,na.rm=TRUE) {
  quantile(x,na.rm=na.rm)[2]
}
Q3 <- function(x,na.rm=TRUE) {
  quantile(x,na.rm=na.rm)[4]
}
```

## `1 (f)` - Vectorized Summary Stats

-   Function that will help apply several summary statistics to our data all at once

-   Contains vector of functions with default to not evaluate if `na`

```{r}

# Vector of functions
myNumericSummary <- function(x){
  c(length(x), n_distinct(x), sum(is.na(x)), mean(x, na.rm=TRUE),
  min(x,na.rm=TRUE), Q1(x,na.rm=TRUE), median(x,na.rm=TRUE), Q3(x,na.rm=TRUE),
  max(x,na.rm=TRUE), sd(x,na.rm=TRUE))
}

# Name of each functions within the vector
statNames <- c('n', 'unique', 'missing', 'mean', 'min', 'Q1', 'median', 'Q3', 'max', 'sd')
```

## `1 (g)` - Apply Summary Stats

-   Apply summary stats function with `summarize` function

```{r}
numericSummary <- housingNumeric %>%
  
  # Apply vector of functions using summarise
  summarise( across( where(is.numeric), ~myNumericSummary(.x) ) )
```

## `1 (h)` - Add Stats Names

-   Combine original data set and the names of each summary statistic

```{r}
numericSummary <- cbind(
  stat=c("n","unique","missing","mean","min","Q1","median","Q3","max","sd"),
  numericSummary
)

# glimpse(numericSummary) # uncomment to see effects
```

\newpage

## `1 (i)` - Pretty up data

### Transform data to make it ready for output format

```{r}
numericSummaryFinal <- numericSummary %>%
  pivot_longer("Id":"ageofGarage", names_to = "variable", values_to = "value") %>%
  pivot_wider(names_from = stat, values_from = value) %>%
  mutate(missing_pct = 100*missing/n,
         unique_pct = 100*unique/n) %>%
  select(variable, n, missing, missing_pct, unique, unique_pct, everything())
```

### Show the output

```{r}
library(knitr)
options(digits=3)
options(scipen=99)
numericSummaryFinal %>% kable()
```

\newpage

## `1 (j)` - Factor Data Report

```{r}
# TODO
```

\newpage

# `2` - Transformation

## `2 (a)` - Fixing Skewed Data

### Function to Convert Skewed Data to Normally Distributed Vector

```{r}
normalizeDist <- function(aVector) {
  
  # Get the optimal lambda. Used later for converting to normal distribution
  normLambda = boxcox(aVector, optimize = TRUE)$lambda

  # Now convert vector to normal distribution, using the optimal lambda
  normalizedVector <- (aVector ** normLambda - 1) / normLambda
  
  return(normalizedVector)
}

# Colors
goodCol = 'darkseagreen3'
badCol  = 'tomato3'
```

### `i.` Fix `LotArea` in Housing Data Set

#### Lot area is highly skewed

```{r}
varTitle = 'Lot Size (Sq. Ft.)'

# See that LotArea is highly skewed
hist(housingData$LotArea, 
      main = varTitle, xlab = varTitle, col = badCol)

# Look at the symbox to see where optimal may lie
symbox(housingData$LotArea, data=housingData, powers=c(3,2,1,0,-0.5,-1,-2),
       ylab = varTitle)

# Normalize the data and store in data
housingData <- housingData %>% 
  mutate(normLotArea = normalizeDist(housingData$LotArea) )
```

#### See the normalized Lot Area variable

-   You can see that the data is definitely more normal

-   However, much of the data is near the median, which may or may not be fine, depending on the analysis

```{r, fig.width=6, fig.height=6}
# Now see the results of the normalization
par(mfrow=c(2,1))

hist( housingData$LotArea, 
      main = paste('Raw', varTitle), xlab = paste('Raw', varTitle), 
      col = badCol )

hist( housingData$normLotArea,
      main = paste('Normalized', varTitle), xlab = paste('Normalized', varTitle), 
      col = goodCol)

```

\newpage

### `i.` Fix `GrLivArea` in Housing Data Set

#### Above Ground Living Area is highly skewed

```{r, fig.height=4}
varTitle = 'Above Ground Living Area (Sq. Ft.)'

# See that LotArea is highly skewed
hist(housingData$GrLivArea, 
      main = varTitle, xlab = varTitle, col = badCol )

# Look at the symbox to see where optimal may lie
symbox(housingData$GrLivArea, data=housingData, powers=c(3,2,1,0,-0.5,-1,-2),
       ylab = varTitle)

# Normalize the data and store in data
housingData <- housingData %>% 
  mutate(normYearBuilt = normalizeDist(housingData$GrLivArea) )
```

#### See the normalized Lot Area variable

-   You can see that the data is definitely more normal

```{r, fig.width=6, fig.height=6}
# Now see the results of the normalization
par(mfrow=c(2,1))

hist( housingData$GrLivArea, 
      main = paste('Raw', varTitle), xlab = paste('Raw', varTitle), 
      col = badCol )

hist( housingData$normYearBuilt,
      main = paste('Normalized', varTitle), xlab = paste('Normalized', varTitle),
      col = goodCol )

```

\newpage

## `2 (b)` - Impute Missing Values

### Function to plot comparison of imputation methods

Highlights of function include:

-   Histogram of actual data, with mean line on x-axis

-   Histogram of imputed data, with mean line on x-axis

-   Regression of actual and imputed data, spread across trival x-axis. Goal is to show variation in data

```{r}
seeImputation <- function(df, df.meanInputed, 
                          imputationMethod) {
  
  # Min/Max ranges so actual and imputed histograms align
  yMin = min(df.meanInputed$y)
  yMax = max(df.meanInputed$y)
  
  # Non Altered data -------------------------------------------------
  
  meanVal = mean(df$y, na.rm=T) # mean of the non altered data
  
  # Create the plot
  p1 <- df %>%
    ggplot(aes(x = y)) +
    
    # Histogram
    geom_histogram(color = 'grey65', fill = 'grey95') +
    
    # The mean value line
    geom_vline(xintercept = meanVal, color = 'tomato3') +
    
    # Text associated with mean value
    annotate("text", 
             label = "Mean Value", 
             x = meanVal, y = 100, 
             size = 5, colour = "tomato3" ) +
    
    # Labels
    labs(title = 'Data with Missing Values',
         y     = 'Frequency', 
         x     = '' ) +
    
    xlim(yMin, yMax) + # min and max range of x axis (for equal comparison)
    theme_minimal() # Theme
  
  
  # Imputed data -------------------------------------------------

  meanValImpute = mean(df.meanInputed$y, na.rm=T)
  
  # Create the plot
  p2 <- df.meanInputed %>%
    ggplot(aes(x = y)) +
    
    # Histogram
    geom_histogram(color = 'grey65', fill = 'grey95') +
    
    # The mean value line
    geom_vline(xintercept = meanVal, color = 'tomato3') +
    
    # Text associated with mean value
    annotate("text", 
             label = "Mean Value", 
             x = meanValImpute, y = 100, 
             size = 5, colour = "tomato3" ) +
    
    # Labels
    labs(title = 'Data without Missing Values',
             subtitle = paste('Using', imputationMethod, 'Imputation Method'),
             y = 'Frequency', 
             x = 'Linear feet of street connected to property') +
    
    xlim(yMin, yMax) + # min and max range of x axis (for equal comparison)
    theme_minimal() # Theme
  
  # Variation scatter ----------------------------------------------------------
  
  p3 <- df.meanInputed %>% ggplot(aes(x=x, y=y, color=missing)) + 
    
    # Add points
    geom_point(alpha = 0.5) +
    
    # Colors, limits, labels, and themes
    scale_color_manual(values = c('grey80', badCol),
                       labels = c('Actuals', 'Imputed') ) +
    ylim(0, quantile(df.meanInputed$y, 0.99)) + # lower 99% of dist
    labs(title   = 'Variation of Actuals vs. Imputed Data',
         x       = 'x', 
         y       = 'Lot Frontage',
         caption =paste0('\nUsing housing.csv data',
                         '\nOnly showing lower 99% of distribution for viewing') 
         ) +
    theme_minimal() + theme(legend.position = 'bottom',
                            legend.title    = element_blank())
  
  
  # Combine the plots for the final returned output
  combinedPlots <- plot_grid(p1, p2, p3, 
                             ncol = 1, label_size = 12,
                             rel_heights = c(1, 1.1, 1.75))
  return(combinedPlots)
}
```

### Create Reusable data set `df`

```{r}
# How much is missing?
missing <- is.na(housingData$LotFrontage)
paste('There are', sum(missing), 'missing values')

# Create a data frame to easily reference the lot frontage for other inputation
df <- data.frame(x = rexp(nrow(housingData)), # meaningless x to help show varation 
                 y = housingData$LotFrontage, 
                 missing = missing)
```

\newpage

### `i` Mean Value Imputation

```{r, fig.height=6.5, warning=FALSE, message=FALSE}
# Create copy of the data with NAs
df.meanInputed <- df  

# Conduct Mean imputation
df.meanInputed[missing,"y"] <- mean(df.meanInputed$y, na.rm=T)

# Compare missing vs. non missing for given imputation method
seeImputation(df, df.meanInputed, imputationMethod = 'Mean')
```

\newpage

### `ii` Regression with Error Imputation

-   Output seems to capture appropriate variance of the actual data.

-   It is clear that the mean does not change

```{r, fig.height=8, warning=FALSE, message=FALSE}
fit <- lm(y ~ x, data = df)    # fit a linear model to the data
f   <- summary(fit)

c  <- f[[4]] # extract the coefficients 
se <- f[[6]] # extract the model standard error

# Regression with NO error
dfReg.imp <- df
dfReg.imp[missing,"y"]<- (c[1] + c[2] * dfReg.imp[missing,"x"])

# Imputation by Regression with error. Note se = standard error of model
df.regErrorImputed <- dfReg.imp %>%
  mutate(y = y + if_else(missing, rnorm(n(), 0, se), 0))

# Compare missing vs. non missing for given imputation method
seeImputation(df, df.regErrorImputed, imputationMethod = 'Regression with Error')
```

\newpage

### `iii` Predictive Mean Matching Imputation

-   Output seems to capture appropriate variance of the actual data.

-   It is clear that the mean does not change much, if at all.

```{r, fig.height=8, warning=FALSE, message=FALSE}
df.pmmImputed <- df # copy data with missingness

# imputation by PMM
df.pmmImputed[missing,"y"] <- mice.impute.pmm( df.pmmImputed$y, 
                                              !df.pmmImputed$missing, 
                                               df.pmmImputed$x)

# Compare missing vs. non missing for given imputation method
seeImputation(df, df.regErrorImputed, 
              imputationMethod = 'Predictive Mean Matching (PMM)')
```

\newpage

## `2 (c)` - Dummy Variable Manipulation

Collapse the factor levels in the Exterior1st down to only five levels -- the first four levels should be the most frequent levels and all other levels should be collapsed into a single "Other" level.

Interpretation

-   Now there are only 5 levels for the `Exterior1st` variable

-   4 most frequent left untouched, and the others grouped in `Other`

```{r}
housingData <- housingData %>%
  
  # lumps all levels except for the n most frequent 
  mutate(Exterior1st = fct_lump_n(Exterior1st, n=4))

# See that there are only 5 levels now
unique(housingData$Exterior1st)
length(unique(housingData$Exterior1st))
```

\newpage

## `2 (d)` - More fun with Factors

### `i` - Get average `SalePrice` for each `Neighborhood` using `tidyverse`

-   Note sorted descending

```{r}
housingData %>%
  group_by(Neighborhood) %>%
  summarise(AvgSalePrice = mean(SalePrice)) %>%
  arrange(desc(AvgSalePrice)) %>% # sort descending on sale price
  kable() # output as a kable table
```

\newpage

### `ii` - Boxplots of Avg. Sale Price by Neighborhood

```{r, fig.height=7, fig.width=10.5}
housingData %>%
  ggplot(aes(x = Neighborhood,
             y = SalePrice) ) +
  
  # Boxplots
  geom_boxplot(color = 'steelblue4', fill = 'lightsteelblue1', alpha = 0.7) +
  
  # Theme, y scale format, and labels
  theme_minimal() + theme(panel.grid.major.x = element_blank()) +
  scale_y_continuous(labels = comma) + 
  labs(title = 'Distribution of Sale Prices by Neighborhood',
       x     = 'Neighborhood',
       y     = 'Sale Price of Home')
```

\newpage

### `iii-iv` - Boxplots Reordered by Descending Sale Price

```{r, fig.height=7, fig.width=10.5}
housingData %>%
  ggplot(aes(x = fct_reorder(Neighborhood, desc(SalePrice) ),
             y = SalePrice) ) +
  
  # Boxplots
  geom_boxplot(color = 'steelblue4', fill = 'lightsteelblue1', alpha = 0.7) +
  
  # Theme, y scale format, and labels
  theme_minimal() + theme(panel.grid.major.x = element_blank()) +
  scale_y_continuous(labels = comma) + 
  labs(title = 'Distribution of Sale Prices by Neighborhood',
       subtitle = 'Ordered Descending by Sale Price of Home',
       x     = 'Neighborhood',
       y     = 'Sale Price of Home')
```
