---
title: "Example of Correlation, Outliers, Nulls, and PCA"
format: 
  gfm:
    toc: true
    toc-depth: 2
editor: visual
---

## Library

```{r}
suppressMessages(library(tidyverse)) 
suppressMessages(library(MASS))      # Animals dataset
suppressMessages(library(ggbiplot))  # biplot or screeplot using ggplot
suppressMessages(library(outliers))  # grubbs.test for outlier detection

```

## Correlations

-   Pearson's correlation does well for `linear` relationships

```{=html}
<!-- -->
```
-   Spearman does well for `non-linear` correlation.

```{r}
# Spearman coefficient
cor(mtcars$cyl, mtcars$mpg, method = 'spearman')
```

## Basic `ggplot`

```{r}
# Plot like a plotter
qplot(data=iris, Sepal.Length)

# GGplot
ggplot(data=iris, aes(x=Sepal.Length,y=Petal.Width)) + 
  geom_point(aes(fill=Species), 
             alpha=I(.75),                               
             position = "jitter",                        
             colour="black",pch=21, size=5) +
  theme_bw() +
  labs(y = "Petal Width (cm)",
       x = "Sepal Length (cm)") +
  theme(legend.key=element_blank(),
        axis.title = element_text(size = 14))

```

## Visualizing Outliers

### Is there an outlier?

-   Note using `grubbs.test` would identify if there is the most outlying data

```{r}
# Is there an outlier? (Exactly one)
outlierTest <- grubbs.test(MASS::Animals$brain)

outlierTest$p.value < 0.05

outlierTest
```

### Visualize the outlier

```{r}
# Visualize Outliers
head(MASS::Animals)

Animals %>%
  ggplot(aes(x =1,
             y = brain)) +

  geom_boxplot() +
  geom_text(label = rownames(Animals))

```

## Understanding Missing Data

```{r}
# Missingness Proportion
df <- mtcars %>%
  dplyr::select(mpg, cyl, hp, qsec)

# Make a missing value dataset
df$mpg[6:15]   <- NA # Make missing vals
df$hp[13:21]   <- NA 
df$qsec[10:18] <- NA

# For a subset of the dataset, what is the missingness proportion?
df.filtered <- df %>%
  filter(cyl == 4)

# See missingness of certain variables
sum(is.na(df.filtered$mpg))  / nrow(df.filtered)
sum(is.na(df.filtered$hp))   / nrow(df.filtered)
sum(is.na(df.filtered$qsec)) / nrow(df.filtered)
```

## Principal Component Analysis using `mtcars`

### Run Analysis

```{r}
# Conduct Principal COmponents
pc<-prcomp(mtcars,
           center = TRUE, # Mean centered  
           scale  = TRUE  # Z-SCore standardized
           )

# What does the data look like for pc's?
pc
```

###  Visualize and Interpret PCA

#### Overview of the Variation Contained

```{r}
# Visualize indivual proportion of variance, for each PC
plot(pc, 
     main = '\nTop 3 Principal Components Explain ~90% of the Variation\nin the Real Data',
     xlab = 'Principal Components (Ordered)')

# pc$rotation

# How much Cumulative variance do each PC hold?
summary(pc) 
```

#### Representativeness for each Variable in Data Set

-   PC1 represents `mpg`, `disp`, and `cyl` very well since nearly parallel with x axis

-   PC2 doesn't do AS good of a job as PC2 (expected since PC1 contains \~60% of the overall variation). However, it helps in representing `carb`, `gear`, and `qsec`

```{r}

# Which PC's represent which variables?
  # E.g., PC1 represents carb and mpg well
ggbiplot(pc,
         obs.scale    = 1, 
         var.scale    = 1, 
         varname.size = 4, 
         labels.size  = 10, 
         circle       = TRUE) +
  
  # Add the names of the cars for context
  geom_text(label = rownames(mtcars), size = 3)
```
