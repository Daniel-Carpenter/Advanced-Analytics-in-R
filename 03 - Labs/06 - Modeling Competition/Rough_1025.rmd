---
title:    "ISE 5103 Intelligent Data Analytics"
subtitle: "Homework 6 - Modeling Competition"
author:   "Daniel Carpenter, Sonaxy Mohanty, & Zachary Knepp"
date:     "October 2022"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    highlight: arrow
    latex_engine: xelatex
  # github_document:
  #   toc: yes
  #   toc_depth: 2
urlcolor: blue
cache: true
fig.width: 7
fig.height: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

```{r error=FALSE, message=FALSE, warning=FALSE}
# Packages --------

# Data Wrangling
library(tidyverse)
library(skimr)
library(lubridate) # dates

# Modeling
library(MASS)
library(caret) # Modeling variants like SVM
library(earth) # Modeling with Mars
library(pls)   # Modeling with PLS
library(glmnet) # Modeling with LASSO

# Aesthetics
library(knitr)
library(cowplot)  # multiple ggplots on one plot with plot_grid()
library(scales)
library(kableExtra)
library(ggplot2)
library(inspectdf)

#Hold-out Validation
library(caTools)

#Data Correlation
library(GGally)
library(regclass)

#RMSE Calculation
library(Metrics)

#p-value for OLS model
library(broom)

#ncvTest
library(car)
```

## General Data Prep
> For general data preparation, please see conceptual steps below. See `.rmd` file for detailed code.

### Read Training Data
Clean data to ensure each read variable has the correct data type (factor, numeric, Date, etc.)
```{r, echo=FALSE}
# Convert all character data to factor
df.train.base <- read.csv('Train.csv', stringsAsFactors = TRUE)
df.test <- read.csv('Test.csv', stringsAsFactors = TRUE)


# convert the ""'s to NA
df.train.base[df.train.base == ""] <- NA

# Clean data
df.train.base <- df.train.base %>% 
  
  # Ensure boolean variables are numeric
  mutate(adwordsClickInfo.isVideoAd = as.numeric(adwordsClickInfo.isVideoAd) ) %>%
  
  # Make sure dates are dates
  mutate(date = as.Date(date),
         visitStartTime = as_datetime(visitStartTime)
         ) %>%

  # Ensure factor are factors
  mutate(custId       = as.factor(custId),
         sessionId    = as.factor(sessionId),
         isTrueDirect = as.factor(isTrueDirect),
         newVisits    = as.factor(if_else(is.na(newVisits), 0, 1) ),
         bounces      = as.factor(if_else(is.na(bounces),   0, 1)   ),
         adwordsClickInfo.page      = as.factor(adwordsClickInfo.page),
         adwordsClickInfo.isVideoAd = as.factor(adwordsClickInfo.isVideoAd)
         ) %>%
  
  dplyr::select(-c(
    isMobile # This is contained in deviceCategory
    
  ))

#view(df.train.base)
```

### Create `numeric` and `factor` *base* `data frames`

Make data set of `numeric` variables called `df.train.base.numeric`
```{r, echo=FALSE}
df.train.base.numeric <- df.train.base %>%

  # selecting all the numeric data
  dplyr::select_if(is.numeric) %>%

  # converting the data frame to tibble
  as_tibble()
```

Make data set of `factor` variables called `df.train.base.factor`
```{r, echo=FALSE}
df.train.base.factor <- df.train.base %>%

  #selecting all the numeric data
  dplyr::select_if(is.factor) %>%

  #converting the data frame to tibble
  as_tibble()
```


## `(a, i)` - Data Understanding
> Create a data quality report of `numeric` and `factor` data  
> Created function called `dataQualityReport()` to create factor and numeric QA report

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Function for data report
dataQualityReport <- function(df) {
  
  # Function to remove any columns with NA
  removeColsWithNA <- function(df) {
    return( df[ , colSums(is.na(df)) == 0] )
  }
  
  # Create Comprehensive data report using skimr package
  # This is done a bit piece-wise because PDF latex does not like the skimr package
  # Very much. So Instead of printing `skim(df)`, I have to pull the contents manually
  # Unfortunately. This is not an issue with html typically.
  dataReport <- skim(df) %>%
    rename_all(~str_replace(.,"skim_","")) %>%
    arrange(type, desc(complete_rate) ) # sort data 
  
  # Filter to the class types
  dataReport.numeric <- dataReport %>% filter(type == 'numeric') # numeric data
  dataReport.factor  <- dataReport %>% filter(type == 'factor' ) # factor  data
  
  # Remove columns that do not apply to this type of data -----------------------
  
  ## numeric data
  dataReport.numeric <- removeColsWithNA(dataReport.numeric)  %>%
    
    # Clean column names by removing numeric prefix, 
    rename_all(~str_replace(.,"numeric.","")) 
    
  ## factor  data
  dataReport.factor  <- removeColsWithNA(dataReport.factor ) %>%
  
    # Clean column names by removing factor  prefix
    rename_all(~str_replace(.,"factor.",""))  
  
  
  # Set up options for Display the reports
  options(skimr_strip_metadata = FALSE)
  options(digits=2)
  options(scipen=99)
  
  # Numeric report <- Get summary of data frame --------------------------------
  
    # data frame stats
    dfStats.num <- data.frame(Num_Numeric_Variables = ncol(df %>% select_if(is.numeric)),
                              Total_Observations    = nrow(df) )
    
    # Now see individual column statistics
    dfColStats.num <- dataReport.numeric %>% 
      dplyr::select(-type, -hist)
    
  
  # Factor report <- Get summary of data frame --------------------------------
  
    # Get summary of data frame
    dfStats.factor <- data.frame(Num_Factor_Variables = ncol(df %>% select_if(is.factor)),
                                 Total_Observations   = nrow(df) )
    
    # Now see individual column statistics
    dfColStats.factor <- dataReport.factor  %>% 
      dplyr::select(-type, -ordered) 
    
    
  # Return the data frames
  return(list('dfStats.num'       = dfStats.num,    
              'dfColStats.num'    = dfColStats.num,
              'dfStats.factor'    = dfStats.factor, 
              'dfColStats.factor' = dfColStats.factor))
}
```

### Numeric Data Quality Report
* `pageviews` has some null values, but there are an insignificant amount, so we will just drop those rows.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Get the factor and numeric reports
initialReport <- dataQualityReport(df.train.base)

# Numeric data frame stats
initialReport$dfStats.num %>% kable()

# Numeric column stats
initialReport$dfColStats.num %>%
  kable() %>% kable_styling(font_size=7, latex_options = 'HOLD_position') # numeric data
```

\newpage

### Factor Data Quality Report
* Location data unknown, so add an `Unknown` label for `null` values
* Appears that few people use website from the ads, which cause many null values. See more details below.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# factor data frame stats
initialReport$dfStats.factor %>% kable()

# factor column stats
initialReport$dfColStats.factor %>%
  kable() %>% kable_styling(font_size=7, latex_options = 'HOLD_position') # numeric data
```

\newpage

### Exploratory Analysis

```{r}
#aggregate revenue
CustRev <- stats::aggregate(df.train.base$revenue, 
                     by=list(df.train.base$custId),
                     FUN = sum,
                     na.rm = TRUE)

#renaming fields
names(CustRev) <- c('custId', 'totalRevenue')

#merging datasets
df.train.merge <- merge(df.train.base, CustRev, by='custId')

#applying transformation
df.train.merge$totalRevenue <- df.train.merge$totalRevenue + 1
df.train.merge$totalRevenue <- log(df.train.merge$totalRevenue)
```


#### Analysis 1: 
  
*   Checking the distribution of the transformation of the aggregrate customer-level sales value
based on the natural log:  

```{r}

hist(df.train.merge$totalRevenue,
     col = 'skyblue4',
     main = 'Distribution of Target Revenue for each customer',
     xlab = 'Target Revenue')
```
  
*   We can see that the transformed revenue doesn't look like a normal distribution with a spike at 0 revenue which means it can be an outlier.  

#### Analysis 2: 
  
*   Correlation between features in the dataset  

```{r}
df.train.merge %>%
  ggplot(aes(x = fct_reorder(channelGrouping, desc(totalRevenue) ),
             y = totalRevenue) ) +
  # Boxplots
  geom_boxplot(aes(color = channelGrouping), fill = 'lightsteelblue1', alpha = 0.7) +
  coord_flip() +
  
  # Theme, y scale format, and labels
  theme_minimal() + 
  theme(panel.grid.major.x = element_blank()) +
  
  #scale_y_continuous(labels = comma) +
  labs(title = 'Distribution of Transformed Revenue by Different Online Store Channels',
       subtitle = 'Ordered Descending by Transformed Revenue Generated by Channels',
       x = 'Channels Used by Customers for Online Store',
       y = 'Transformed Revenue Generated')
```


\newpage

## `(a, ii)` - Data Preparation
> For general data preparation, please see conceptual steps below. See `.rmd` file for detailed code.

### Clean up Null Data

See that when `region` is `Osaka Prefecture` and `city` is `Osaka` some location details are `NULL` 

* Implication: the other fields can be manually set to correct values based on region and city criteria  
  
* So, set `location related` null fields to `know` description for the above `region` and `city` condition

```{r, echo=FALSE, results='hide'}

# df.train.base[!complete.cases(df.train.base$continent), ] %>%
#   distinct(continent, subContinent, country, region, metro, city)
# 
# 
# df.train.base %>%
#   filter(region == 'Osaka Prefecture') %>%
#   distinct(continent, subContinent, country, metro, city, region)

df.train <- df.train.merge


df.train$continent[is.na(df.train$continent) &
           df.train$region == 'Osaka Prefecture'] <- 'Asia'

# df.train %>%
#   filter(region == 'Osaka Prefecture' & city == 'Osaka') %>%
#   distinct(subContinent)

df.train$subContinent[is.na(df.train$subContinent) &
           df.train$region == 'Osaka Prefecture' &
             df.train$city == 'Osaka'] <- 'Eastern Asia'

# df.train %>%
#   filter(region == 'Osaka Prefecture' & city == 'Osaka') %>%
#   distinct(country)

df.train$country[is.na(df.train$country) &
           df.train$region == 'Osaka Prefecture' &
             df.train$city == 'Osaka'] <- 'Japan'
  
# df.train %>%
#   filter(region == 'Osaka Prefecture' & city == 'Osaka') %>%
#   distinct(metro)

# df.train %>%
#   filter(metro == 'JP_KINKI')

df.train$metro[is.na(df.train$metro) &
           df.train$region == 'Osaka Prefecture' &
             df.train$city == 'Osaka'] <- 'JP_KINKI'
```
  
See that when `continent` is `null`, then other `location` related fields are also null  

* Implication: these other fields depend on the `continent` variable  

* So, set `location related` null fields to `Unknow` description 

```{r, echo=FALSE}
# If null in location data, then 'Unknown' location
df.train <- df.train %>%
  mutate_at(
    # Only mutate these location variables
    vars(continent:city), 
    
    # Apply function rename null values to Unknown
    list(~ as.factor(ifelse(is.na(.), 'Unknown', .) ) ) 
  )
```

  
See that when `medium` is `null`, then other `ad`, `keyword` and `campaign` related fields are (mostly) null  

* Implication: these other fields depend on the `medium` variable

* So, set these null fields to `None` description, since a null value indicates
the user did not has `no traffic source`  

```{r, echo=FALSE}
# Now clean up the data in the main data frame `df.train`
# by setting null values to "No taffic source" if there is no medium
# Applies to "ad*", keyword, and campaign, referralPath, medium variables
df.train <- df.train %>%
  mutate_at(
    # Only mutate the variables starting with ad, THEN the campaign variable
    vars(starts_with('ad'), keyword, campaign, referralPath, medium), 
    
    # Apply function rename set the campaign text if campaign is null
    list(~ as.factor(ifelse(is.na(medium), 'No traffic source ', .) ) ) 
  ) 
```

See that when `campaign` is `null`, then some `ad` related fields are (mostly) null  

* Implication: these other fields depend on the `campaign` variable

* So, set `adwordsClickInfo.page` null fields to `None` description, since a null value indicates
the user did not come using an advertisement  

```{r, echo=FALSE}
# Now clean up the data in the main data frame `df.train`
# by setting null values to "None" if there is no campaign.
# Applies to "ad*", keyword, and campaign variables
df.train <- df.train %>%
  mutate_at(
    # Only mutate the variables starting with ad, THEN the campaign variable
    vars(adwordsClickInfo.page, adwordsClickInfo.slot, adwordsClickInfo.adNetworkType, adwordsClickInfo.isVideoAd, campaign), 
    
    # Apply function rename set the campaign text if campaign is null
    list(~ as.factor(ifelse(is.na(campaign), 'No Campaign', .) ) ) 
  ) 

```

Similar to campaign, whenever `keyword` is NA, some `ads` is null  
```{r, echo=FALSE}
#NO_KEYWORD_TEXT = 'No Keyword'

# Now clean up the data in the main data frame `df.train`
# by setting null values to "No Keyword" if there is no keyword
# Applies to some "ad*", and keyword variables
df.train <- df.train %>%
  mutate_at(
    # Only mutate the variables starting with ad, THEN the keyword variable
    vars(adContent, adwordsClickInfo.adNetworkType, adwordsClickInfo.isVideoAd, keyword), 
    
    # Apply function rename set the campaign text if campaign is null
    list(~ as.factor(ifelse(is.na(keyword), 'No Keyword', .) ) ) 
  ) 
```

Similar to the campaign data, if the `adContent` is null, label as `No Ad`. 
  
*   Implications: If there is no ad Content of the traffic source then there is no no referral path  

```{r, echo=FALSE}
# If the `adContent` is null, label as `None`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(referralPath, adContent), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(adContent), 'No Ad', .) ) ) 
  )
```

Similar to the campaign data, if the `adwordsClickInfo.adNetworkType` is null, then all `ad` related variables are also `NULL`. 
  
*   Implications: If there is no ad search then customer didn't see any ad.  

```{r, echo=FALSE}
# If the `adwordsClickInfo.adNetworkType` is null, label as `No Ad Network`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(adwordsClickInfo.page, adwordsClickInfo.slot, adwordsClickInfo.gclId,
         adwordsClickInfo.isVideoAd, adwordsClickInfo.adNetworkType), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(adwordsClickInfo.adNetworkType), 'No Ad Network', .) ) ) 
  )
```

Similar to the adwordsClickInfo.adNetworkType data, if the `adwordsClickInfo.page` is null, then some `ad` related variables are also `NULL` and there is no referral source. 
  
*   Implications: If there is no ad published on a page then customer didn't see any ad.  

```{r, echo=FALSE}
# If the `adwordsClickInfo.page` is null, label as `No Ad Page`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(referralPath, adwordsClickInfo.slot, adwordsClickInfo.gclId, adwordsClickInfo.page), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(adwordsClickInfo.page), 'No Ad Page', .) ) ) 
  )
```

If `network domain` is `NULL` then all the related domains are also NULL. 
```{r, echo=FALSE}
# If the `network domain` is null, label as `No Domain`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(networkDomain:topLevelDomain), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(.), 'No Domain', .) ) ) 
  )
```


Setting `referralPath` for NAs. 
```{r, echo=FALSE}
# If the `network domain` is null, label as `No Domain`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(referralPath), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(referralPath), 'No Referrer', .) ) ) 
  )
```

Setting `adwordsClickInfo.gclId` for NAs. 
```{r, echo=FALSE}
# If the `network domain` is null, label as `No Domain`
df.train <- df.train %>%
  mutate_at(
    # Only mutate the referral path
    vars(adwordsClickInfo.gclId), 
    
    # Apply function rename set the referral to none
    list(~ as.factor(ifelse(is.na(adwordsClickInfo.gclId), 'No Google Click ID', .) ) ) 
  )
```

Now we have very few null values rows. Let's simply remove them. See below for how many.
```{r, echo=FALSE}
# Number of rows with any nulls
numRowsWithNulls <- nrow(df.train[!complete.cases(df.train), ])

# Output text
paste('There are', numRowsWithNulls, 'rows with nulls')
paste0('That equates to ', round(numRowsWithNulls / nrow(df.train)* 100, 1), '% rows with nulls')

# Drop the rows
df.train <- df.train %>% drop_na()
paste('Total Rows Remaining:', nrow(df.train))
```

```{r, eval=FALSE, echo=FALSE}
# Check the data set - see that most of the ad data is now cleaned.
# report12 <- dataQualityReport(df.train)
# report12$dfColStats.factor %>% kable()
```


```{r, echo=FALSE}
df.train.clean <- df.train

# Make data set of `factor` variables called `df.train.base.factor`
df.train.factor <- df.train %>%

  # selecting all the numeric data
  dplyr::select_if(is.factor) %>%

  # converting the data frame to tibble
  as_tibble()

# Get list of factors and the number of unique values
factorCols <-
  as.data.frame(t(df.train.factor %>% summarise_all(n_distinct))) #%>%
  # kable()

# We are going to factor collapse factor columns with more than 4 columns
# So there will be 5 of the original, and 1 containing 'other'
# This is the threshold
factorThreshold = 8

# Get a list of the factors we are going to collapse
colsWithManyFactors <- rownames(factorCols %>% filter(V1 > factorThreshold))

# Show a summary of how many factors will be collapsed
numberOfColsWithManyFactors = length(colsWithManyFactors)
paste('Before cleaning, there are', numberOfColsWithManyFactors, 'factor columns with more than',
      factorThreshold, 'unique values')

# Collapse the affected factors in the original data (the one that already has imputation)
## for each factor column that we are about to collapse
# The third column is omits the cutstomer ID and session ID
FIRST_NON_CUST_SESSION_IDX = 3
for (collapsedColNum in FIRST_NON_CUST_SESSION_IDX:numberOfColsWithManyFactors) {

  # The name of the column with null values
  nameOfThisColumn <- colsWithManyFactors[collapsedColNum]

  # Get the actual data of the column with nulls
  colWithManyFactors <- df.train[, nameOfThisColumn]

  # lumps all levels except for the n most frequent
  df.train.clean[, nameOfThisColumn] <- fct_lump_n(colWithManyFactors,
                                                   n=factorThreshold)
}
# Check to see if the factor lumping worked
factorColsCleaned <-
  t(df.train.clean %>%
                       select_if(is.factor) %>%
                       summarise_all(n_distinct))
paste('After cleaning, there are', sum(factorColsCleaned > factorThreshold + 1, na.rm = TRUE),
      "columns with more than", factorThreshold + 1, "unique values (omitting NA's)")
```

\newpage

```{r, echo=FALSE}
#Cleaning up some  variables no longer needed
rm(CustRev,
   numRowsWithNulls,
   df.train.base,
   df.train.base.factor,
   df.train.base.numeric,
   df.train.merge,
   factorCols,
   factorColsCleaned,
   FIRST_NON_CUST_SESSION_IDX,
   factorThreshold,
   nameOfThisColumn,
   numberOfColsWithManyFactors,
   collapsedColNum,
   colsWithManyFactors
)
```
## `(a, iii)` - Modeling

### OLS Model

#### Fit the Model
```{r}
# Tee OLS model
ols <- lm(totalRevenue ~ pageviews+visitNumber+
            referralPath+deviceCategory+region+metro+city
          +channelGrouping+campaign+keyword+medium, 
          data =df.train.clean) 
```

#### View and Interpret Results
```{r, echo=FALSE, results='hide'}
# Key diagnostics for OLS: lm final summary table
summary(ols)
#plot(ols)

# Key diagnostics
ols.rmse    <- rmse(actual=df.train.clean$totalRevenue, predicted=ols$fitted.values)
ols.summary <- summary(ols)
```

```{r, echo=FALSE}
# Get the RMSE and R Squared of the model
keyDiagnostics.ols <- data.frame(Model    = 'OLS',
                                 Notes    = 'lm',
                                 Hyperparameters = 'N/A',
                                 RMSE     = ols.rmse,
                                 Rsquared = ols.summary$adj.r.squared)

# Show output
keyDiagnostics.ols %>% 
  knitr::kable()
``` 


\newpage

### Model 2: PCR Model

#### Fit the Model
```{r, echo=FALSE, results='hide'}
# copy data
pcr.df <- df.train.clean
  

pcr <- pcr(totalRevenue ~ pageviews+visitNumber+
            referralPath+deviceCategory+region+metro+city,

          data=pcr.df, scale=TRUE, validation="CV")
```


#### View and Interpret Results
```{r, echo=FALSE, results='hide'}
# See the summary output
summary(pcr)

validationplot(pcr)
validationplot(pcr, val.type = 'R2')

# Note saw that 15 components explain 75% of variance
```
  
```{r, echo=FALSE}
# Key diagnostics for PCR final summary table
RMSE.pcr <- RMSEP(pcr, ncomp=15)
R2.pcr <- R2(pcr, ncomp = 1:15)

# Get the RMSE and R Squared of the model
keyDiagnostics.pcr <- data.frame(Model    = 'PCR',
                                 Notes    = 'pcr',
                                 Hyperparameters = paste('ncomp = ', pcr$ncomp),
                                 RMSE     = min(RMSE.pcr$val),
                                 Rsquared = max(R2.pcr$val) )

# Show output
keyDiagnostics.pcr %>% 
  knitr::kable()
```  

\newpage

### Model 3: MARS

#### Fit the Model
```{r, echo=FALSE, results='hide'}
marsFit <- train(data = df.train.clean, 
                 totalRevenue ~ pageviews+visitNumber+
                   referralPath+deviceCategory+region+metro+city,
                  method     = "earth",             # Radial kernel
                  tuneLength = 9,                   # 9 values of the cost function
                  preProc    = c("center","scale"), # Center and scale data
                  trControl  = ctrl
                 )
summary(marsFit)
#plot(marsFit)
```

#### View and Interpret Results
```{r, echo=FALSE}
# Key diagnostics for final model

# Get the RMSE and R Squared of the model
hyperparameters.mars = list('degree' = marsFit[["bestTune"]][["degree"]],
                            'nprune' = marsFit[["bestTune"]][["nprune"]])

keyDiagnostics.mars <- data.frame(Model   = 'MARS',
                                  Notes    = 'caret and earth',
                                  Hyperparameters = paste('Degree =', hyperparameters.mars$degree, ',',
                                                          'nprune =', hyperparameters.mars$nprune)
                                  )

keyDiagnostics.mars <- cbind(keyDiagnostics.mars,
                            marsFit$results %>% 
                              filter(degree == hyperparameters.mars$degree,
                                     nprune == hyperparameters.mars$nprune) %>%
                              dplyr::select(RMSE, Rsquared)
                      )

# Show output
keyDiagnostics.mars %>% kable()
```

\newpage

### Model 4: Elastic Net Model

#### Fit the Model
```{r, warning=FALSE, message=FALSE}
# Train and tune the Elastic net

rm(df.train.clean.factor)
rm(df.train.clean.numeric)

fit.elasticnet <- train(data = df.train.clean, 
                 totalRevenue ~ pageviews+visitNumber+
                   referralPath+deviceCategory+region+metro+city,
                 method     = "glmnet",         # Elastic net
                 preProc    = c("center","scale"), # Center and scale data
                 tuneLength = 10,  #10 values of alpha and 10 lambda values for each
                 trControl  = ctrl)
```  

#### View and Interpret Results
```{r, echo=FALSE}
# Function to get the best hypertuned parameters
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
result.elasticnet <- get_best_result(fit.elasticnet)

# Gather key diagnostics for summary table
# Get the RMSE and R Squared of the model
hyperparameters.elasticnet = list('Alpha'  = result.elasticnet$alpha,
                                  'Lambda' = result.elasticnet$lambda)


keyDiagnostics.elasticnet <- data.frame(Model    = 'Elastic Net',
                                        Notes    = 'caret and elasticnet',
                                        Hyperparameters = paste('Alpha =',
                                                                hyperparameters.elasticnet$Alpha, ',',
                                                                'Lambda =',
                                                                hyperparameters.elasticnet$Lambda),
                                        RMSE     = result.elasticnet$RMSE,
                                        Rsquared = result.elasticnet$Rsquared
                                        )

# Show output
keyDiagnostics.elasticnet %>% knitr::kable()
```

\newpage

## `(a, iv)` - Debrief

### Summary Table
```{r, echo=FALSE}
# Add the key diagnostics here
rbind(
  keyDiagnostics.ols,
  keyDiagnostics.pcr,
  keyDiagnostics.mars,
  keyDiagnostics.elasticnet
  ) %>%
  
  # Round to 4 digits across numeric data
  mutate_if(is.numeric, round, digits = 4) %>%
  
  # Spit out kable table
  kable()
```

### Interpretations of Debrief
