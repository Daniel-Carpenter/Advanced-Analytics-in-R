---
title: "Handling Missing Data"
author: "Daniel Carpenter"
format: 
  gfm:
    toc: true
    number-sections: true
    toc-depth: 2
standalone: true
    
editor: visual
---

# Deletion and Indicators

## Summary

![](images/paste-CE124352.png){width="550"}

## Single Imputation

### How to determine missingness cause?

> Example in R

![](images/paste-E5A3A1B5.png){width="550"}

+-------------+---------------------------------------------------------------------+
| **MAR**     | Missing values in `y` depend on `x`, which x *is in* the data       |
+=============+=====================================================================+
| **MNAR**    | Missing values in `y` depend on `y` (itself)                        |
+-------------+---------------------------------------------------------------------+
| **MCAR**    | Missing values in `y` depend on `z`, which `z` *is NOT* in the data |
+-------------+---------------------------------------------------------------------+

### Handling Missingness - Basic/Simple Approaches

-   Note most imputation assumes MCAR or MAR

-   Can hurt the variance if not used well.

-   Nothing is perfect

![](images/paste-752F6FFF.png){width="550"}

+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+
| Handling                            | Description                                                                   | Implication                                                               | Example                                |
+=====================================+===============================================================================+===========================================================================+========================================+
| Listwise                            | Delete entire record if there are nulls                                       | Less data                                                                 | `newdata <- na.omit(mydata)`           |
+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+
| Pairwise Deletion                   | Use all cases if available, for each column.                                  | Hard to compare columns                                                   | `mean(column,  na.rm=TRUE`             |
+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+
| Indicators                          | Create new binary `1/0` indicating missing values, or could create new factor | Produces biased estimates since likely does not represent true variance   |                                        |
|                                     |                                                                               |                                                                           |                                        |
| *DO NOT USE THIS FOR MOST ANALYSIS* |                                                                               |                                                                           |                                        |
+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+
| Single Value Imputation             | Missing value changed with the mean, median                                   | Produces biased estimates since likely does not represent *true* variance |                                        |
+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+
| Stratified Imputation               | Impute based on groupings                                                     | Less bad than single                                                      | Average income for male, females, etc. |
+-------------------------------------+-------------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------+

### Handling Missingness - Predictive Approaches

![](images/paste-7C541A82.png){width="550"}

+--------------------------+---------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------+
| Handling                 | Description                                                               | Implication                                                                                                                                    | Example                        |
+==========================+===========================================================================+================================================================================================================================================+================================+
| Regression               | Build regression from non missing data. Then predict the values           | Trend is good, but it reduces error                                                                                                            |                                |
+--------------------------+---------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------+
| Regression with Error    | Same as above, but include the `residual standard error` from model       | Still deflates variance, and cannot usually test success. Similar trend with realistic error, similar to original data. Does not restain range |                                |
+--------------------------+---------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------+
| Predictive mean matching | Hybrid between regression, but also includes the range of current dataset | Better than prior, but can create ranges of variance that are incorrect.                                                                       | ![](images/paste-48081196.png) |
+--------------------------+---------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------+
| kNN                      | Uses distance calclulation to discover closest data to missing one        | Increased neighbors will be similar to mean imputation                                                                                         | ![](images/paste-4CE0562F.png) |
+--------------------------+---------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------+

### Single Imputation in R

```{r, cache=TRUE, message=FALSE}
#Example of single imputation techniques for ISE 5103 Intelligent Data Analytics
#Charles Nicholson
#September 2015

#load appropriate libraries
library(VIM)
library(mice)


# CREATE A SET OF FAKE DATA  (y ~ x) ------------
x<-rexp(1000)
y<-0.5*rnorm(1000) + 0.5*x       
z<-runif(1000)

alpha<-runif(1000) # not included in dataframe
beta<-runif(1000)  # not included in dataframe

df<-data.frame(x,y,z)

xmax<-ceiling(max(df$x))
ymax<-ceiling(max(df$y))
ymin<-floor(min(df$y))


#scatterplot would look like this if there were NO MISSING INFORMATION
plot(df$x,df$y,ylim=c(ymin,ymax), xlim=c(0,xmax) , xlab="x", ylab="y")

# now lets create some missing values....
dfMiss <- df

dfMiss[df$y>1.30,"y"]<-NA           #MNAR
dfMiss[alpha<0.2,"z"]<-NA           #MCAR
dfMiss[beta>0.90,"y"]<-NA           #MCAR
dfMiss[df$x>2.65,"y"]<-NA           #MAR

missing <- is.na(dfMiss$y)
sum(missing)
dfMiss$missing <- missing

#scatterplot now looks like this...
plot(dfMiss$x,dfMiss$y,ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")


#imputaion by "hotdeck" --------------------------------------------------------
dfHD.imp <- dfMiss

#sample m values from from the non-missing data (with replacement)
hotdeck <- dfHD.imp[!missing,"y"]  # create sample pool

n <- length(hotdeck)    #size of sample pool
m <- sum(missing)    #how many samples do I need?

hotdeck <- hotdeck[sample(n,m,replace=TRUE)]

dfHD.imp[missing,"y"]<-hotdeck

plot(df$x,df$y,ylim=c(-1.3,4.25))    #plot of all data (no missings)

#plot data with hotdeck imputation -- imputed values in red
plot(dfHD.imp$x, dfHD.imp$y, col = factor(dfHD.imp$missing), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")

par(mfrow=c(2,1))   #setup graphics device to make two plots on the screen

hist(df$y, xlim=c(-1,xmax), main="All Data", xlab="x")   #histogram of all data
trueMV<-round(mean(df$y),3)                               
trueVar<-round(var(df$y),3)
abline(v = trueMV, col = "blue", lwd = 2)                    # add a line for the mean
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar)) # add text for mean and var

hist(dfHD.imp$y, xlim=c(-1,xmax), main="Hot Deck", xlab="x")
mv<-round(mean(dfHD.imp$y),3)
svar<-round(var(dfHD.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 100, label=paste("Mean:",mv, "  Var:", svar))

par(mfrow=c(1,1))   # reset graphics device to the default 1 plot



#imputation by mean ---------------------------------------------------------

dfMean.imp<-dfMiss  #copy of the data with missings

dfMean.imp[missing,"y"]<-mean(dfMean.imp$y,na.rm=T)   #imputation by mean


par(mfrow=c(2,1))
hist(df$y, xlim=c(-1,xmax), main="All Data", xlab="x")
abline(v = trueMV, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar))

hist(dfMean.imp$y, xlim=c(-1,xmax), main="Mean Imputation", xlab="x")
mv<-round(mean(dfMean.imp$y),3)
svar<-round(var(dfMean.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",mv, "  Var:", svar))
par(mfrow=c(1,1))

plot(dfMean.imp$x, dfMean.imp$y, col = factor(dfMean.imp$missing), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")



#imputation by "regression"  ---------------------------------------------

fit<-lm(dfMiss$y~dfMiss$x)    # fit a linear model to the data
f<-summary(fit)
print (f)  

str(f)

c<-f[[4]]                     # extract the coefficients 
se<-f[[6]]                    # extract the model standard error

dfReg.imp <- dfMiss
dfReg.imp[missing,"y"]<- (c[1] + c[2]*dfReg.imp[missing,"x"])   #imputataion with regression


par(mfrow=c(2,1))
hist(df$y, xlim=c(-1,xmax), main="All Data", xlab="x")
abline(v = trueMV, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar))

hist(dfReg.imp$y, xlim=c(-1,xmax), main="Regression Imputation", xlab="x")
mv<-round(mean(dfReg.imp$y),3)
svar<-round(var(dfReg.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",mv, "  Var:", svar))

par(mfrow=c(1,1))

plot(dfReg.imp$x, dfReg.imp$y, col = factor(dfReg.imp$missing),ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")



# USE THE mice PACKAGE FOR Predictive Mean Matching (PMM) -----------------------
dfPMM.imp <- dfMiss

#imputation by PMM
dfPMM.imp[missing,"y"] <- mice.impute.pmm(dfPMM.imp$y, !dfPMM.imp$missing, dfPMM.imp$x)

plot(dfPMM.imp$x, dfPMM.imp$y, col = factor(dfPMM.imp$missing), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")

par(mfrow=c(2,1))
hist(df$y, xlim=c(-1,xmax),main="All Data", xlab="x")
abline(v = trueMV, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar))

hist(dfPMM.imp$y, xlim=c(-1,xmax), main="Predictive Mean Matching", xlab="x")
mv<-round(mean(dfPMM.imp$y),3)
svar<-round(var(dfPMM.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 80, label=paste("Mean:",mv, "  Var:", svar))
par(mfrow=c(1,1))



#imputation by "regression" plus random error -------------------------

dfRegErr.imp <- dfReg.imp

#imputation by regression with error (remember that se = standard error of model)
dfRegErr.imp[missing,"y"] <- dfRegErr.imp[missing,"y"] + rnorm(sum(missing),0,se**2)

par(mfrow=c(2,1))
hist(df$y, xlim=c(-1,xmax), main="All Data", xlab="x")
abline(v = trueMV, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar))

hist(dfRegErr.imp$y, xlim=c(-1,xmax), main="Regression Imputation with Error", xlab="x")
mv<-round(mean(dfRegErr.imp$y),3)
svar<-round(var(dfRegErr.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",mv, "  Var:", svar))

par(mfrow=c(1,1))

plot(dfRegErr.imp$x, dfRegErr.imp$y, col = factor(dfRegErr.imp$missing), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")



# k-nearest neighbor from VIM package (kNN imputation) ----------------------------

dfKNN.imp <- kNN(dfMiss[,1:3],k=5)
plot(dfKNN.imp$x, dfKNN.imp$y, col = factor(dfKNN.imp$y_imp), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")

par(mfrow=c(2,1))
hist(df$y, xlim=c(-1,xmax), main="All Data", xlab="x")
abline(v = trueMV, col = "blue", lwd = 2)
text(4, 205, label=paste("Mean:",trueMV, "  Var:", trueVar))

hist(dfKNN.imp$y, xlim=c(-1,xmax), main="k-Nearest Neighbor", xlab="x")
mv<-round(mean(dfKNN.imp$y),3)
svar<-round(var(dfKNN.imp$y),3)
abline(v = mv, col = "blue", lwd = 2)
text(4, 100, label=paste("Mean:",mv, "  Var:", svar))

par(mfrow=c(1,1))


# for fun, try kNN with 400 neighbors....  it takes a few seconds...

dfKNN400.imp <- kNN(dfMiss[,1:3],k=400)
plot(dfKNN400.imp$x, dfKNN400.imp$y, col = factor(dfKNN400.imp$y_imp), ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")



#in summary...

par(mfrow = c(2,2))
plot(df$x,df$y,ylim=c(-1.3,4.25), main="All Data")
plot(dfMean.imp$x, dfMean.imp$y, col = factor(dfMean.imp$missing), main="Mean", ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")
plot(dfHD.imp$x, dfHD.imp$y, col = factor(dfHD.imp$missing), main="Hot Deck", ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")
plot(dfReg.imp$x, dfReg.imp$y, col = factor(dfReg.imp$missing), main="Regression", ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")

plot(df$x,df$y,ylim=c(-1.3,4.25), main="All Data")
plot(dfPMM.imp$x, dfPMM.imp$y, col = factor(dfPMM.imp$missing),  main="Predictive Mean Matching",ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")
plot(dfKNN.imp$x, dfKNN.imp$y, col = factor(dfKNN.imp$y_imp),  main="k-Nearest Neighbors", ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")
plot(dfRegErr.imp$x, dfRegErr.imp$y, col = factor(dfRegErr.imp$missing) , main="Regression with Random Error",ylim=c(ymin,ymax), xlim=c(0,xmax), xlab="x", ylab="y")
```

## Multiple Imputation

### Steps

![](images/paste-1FB21749.png){width="550"}

![](images/paste-184564F2.png){width="550"}

![](images/paste-48743776.png){width="550"}

![](images/paste-1F97A760.png){width="550"}

![](images/paste-62405CCD.png){width="550"}

![](images/paste-78D2A36E.png){width="550"}

![](images/paste-73F43BF5.png){width="550"}

![](images/paste-4F48D3A7.png){width="550"}

### Iterative Approach

![](images/paste-E9CE03AE.png){width="550"}

## Maximum Likelihood

![](images/paste-59B715D4.png){width="550"}

![](images/paste-D0424C25.png){width="550"}

![](images/paste-F663E9C6.png){width="550"}

## Multiple Imputation in R

```{r}
rm(list = ls())

# Example code to demonstrate multivariate imputation by chained equations (mice)
# ISE 5103 Intelligent Data Analytics
# Charles Nicholson
# September 2015


# the package mice: multivariate imputation by chained equations
library(mice)


# create some random sample data 
#-------------------------------------------------
n=100   #n equals the number of observations

#four variables
x1<-5*runif(n)
x2<- rnorm(n) + runif(n) - 0.5*x1
x3<-x1+2*rexp(n) + rnorm(n)
x4<-x1+x2+2*runif(n) + rnorm(n)

# let y be some function of x1, x2, and x3
y<-5*x1+4*x2+2*x3+rnorm(n)


# create a data frame from the vectors
df<-data.frame(y,x1,x2,x3,x4)

dfFull<-df  #save the full data for later use
#-------------------------------------------------


# introduce some missingness in the data for multiple variables using different rules
#-------------------------------------------------
df[y<10,"x1"]<-NA

u<-runif(n)
df[u*y>10,"x1"]<-NA

df[y+5*x3-x4 > 50,"x2"]<-NA

u<-runif(n)
df[(y*u+x3+x2) > 15,"x1"]<-NA

df[x3+x1<3,"y"]<-NA

u<-runif(n)
df[((y+x3+x1)*u > 15 & (y+x3+x1)*u < 50),"x4"]<-NA

#check the percent missing per variable
myfun<-function(x) mean(is.na(x))
apply(df,2,myfun)
#-------------------------------------------------


# perform the first two steps of MI using the "mice" command 
# create m=6 data sets and impute missing values 
imp<-mice(df,m=6,meth="norm.nob")

# the output object is quite complex!
str(imp)

#take a look at how the means and variances of the imputed values are (hopefully) converging 
imp$chainMean
imp$chainVar

#can plot those means and variances
plot(imp)

# perform the third step of MI using the "with" command
# to perform a standard analysis (in this case, a linear regression) on each data set 
fit<-with(imp, lm(y~x1+x2+x3+x4))

#perfrom the fourth step of MI, recombination, using the "pool" command 
est<-pool(fit)


plot(dfFull)      #pairs plot of full data
plot(df)          #pairs plot of available cases
plot(na.omit(df)) #pairs plot for complete cases


#coefficient estimates based on full data (before creating missingness)
summary(fullfit<-lm(data=dfFull,y~x1+x2+x3+x4))

#coefficient estimates based on complete cases (no imputation)
summary(missfit<-lm(data=df,y~x1+x2+x3+x4))

#coefficient estimates based on MICE (recombined estimates)
summary(est)
```

## 
